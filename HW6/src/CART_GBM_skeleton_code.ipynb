{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
    "import graphviz\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = np.loadtxt('svm-train.txt')\n",
    "data_test = np.loadtxt('svm-test.txt')\n",
    "x_train, y_train = data_train[:, 0: 2], data_train[:, 2].reshape(-1, 1)\n",
    "x_test, y_test = data_test[:, 0: 2], data_test[:, 2].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change target to 0-1 label\n",
    "y_train_label = np.array(list(map(lambda x: 1 if x > 0 else 0, y_train))).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training classifiers with different depth\n",
    "clf1 = Classification_Tree(max_depth=1)\n",
    "clf1.fit(x_train, y_train_label)\n",
    "\n",
    "clf2 = Classification_Tree(max_depth=2)\n",
    "clf2.fit(x_train, y_train_label)\n",
    "\n",
    "clf3 = Classification_Tree(max_depth=3)\n",
    "clf3.fit(x_train, y_train_label)\n",
    "\n",
    "clf4 = Classification_Tree(max_depth=4)\n",
    "clf4.fit(x_train, y_train_label)\n",
    "\n",
    "clf5 = Classification_Tree(max_depth=5)\n",
    "clf5.fit(x_train, y_train_label)\n",
    "\n",
    "clf6 = Classification_Tree(max_depth=6)\n",
    "clf6.fit(x_train, y_train_label)\n",
    "\n",
    "# Plotting decision regions\n",
    "x_min, x_max = x_train[:, 0].min() - 1, x_train[:, 0].max() + 1\n",
    "y_min, y_max = x_train[:, 1].min() - 1, x_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "f, axarr = plt.subplots(2, 3, sharex='col', sharey='row', figsize=(10, 8))\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1], [0, 1, 2]),\n",
    "                        [clf1, clf2, clf3, clf4, clf5, clf6],\n",
    "                        ['Depth = {}'.format(n) for n in range(1, 7)]):\n",
    "\n",
    "    Z = np.array([clf.predict_instance(x) for x in np.c_[xx.ravel(), yy.ravel()]])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha=0.4)\n",
    "    axarr[idx[0], idx[1]].scatter(x_train[:, 0], x_train[:, 1], c=y_train_label, alpha=0.8)\n",
    "    axarr[idx[0], idx[1]].set_title(tt)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare decision tree with tree model in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split=5)\n",
    "clf.fit(x_train, y_train_label)\n",
    "export_graphviz(clf, out_file='tree_classifier.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize decision tree\n",
    "!dot -Tpng tree_classifier.dot -o tree_classifier.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(filename='tree_classifier.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit regression tree to one-dimensional regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_krr_train = np.loadtxt('krr-train.txt')\n",
    "data_krr_test = np.loadtxt('krr-test.txt')\n",
    "x_krr_train, y_krr_train = data_krr_train[:,0].reshape(-1,1),data_krr_train[:,1].reshape(-1,1)\n",
    "x_krr_test, y_krr_test = data_krr_test[:,0].reshape(-1,1),data_krr_test[:,1].reshape(-1,1)\n",
    "\n",
    "# Training regression trees with different depth\n",
    "clf1 = Regression_Tree(max_depth=1,  min_sample=1, loss_function='mae', estimator='median')\n",
    "clf1.fit(x_krr_train, y_krr_train)\n",
    "\n",
    "clf2 = Regression_Tree(max_depth=2,  min_sample=1, loss_function='mae', estimator='median')\n",
    "clf2.fit(x_krr_train, y_krr_train)\n",
    "\n",
    "clf3 = Regression_Tree(max_depth=3,  min_sample=1, loss_function='mae', estimator='median')\n",
    "clf3.fit(x_krr_train, y_krr_train)\n",
    "\n",
    "clf4 = Regression_Tree(max_depth=4,  min_sample=1, loss_function='mae', estimator='median')\n",
    "clf4.fit(x_krr_train, y_krr_train)\n",
    "\n",
    "clf5 = Regression_Tree(max_depth=5,  min_sample=1, loss_function='mae', estimator='median')\n",
    "clf5.fit(x_krr_train, y_krr_train)\n",
    "\n",
    "clf6 = Regression_Tree(max_depth=6,  min_sample=1, loss_function='mae', estimator='median')\n",
    "clf6.fit(x_krr_train, y_krr_train)\n",
    "\n",
    "plot_size = 0.001\n",
    "x_range = np.arange(0., 1., plot_size).reshape(-1, 1)\n",
    "\n",
    "f2, axarr2 = plt.subplots(2, 3, sharex='col', sharey='row', figsize=(15, 10))\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1], [0, 1, 2]),\n",
    "                        [clf1, clf2, clf3, clf4, clf5, clf6],\n",
    "                        ['Depth = {}'.format(n) for n in range(1, 7)]):\n",
    "\n",
    "    y_range_predict = np.array([clf.predict_instance(x) for x in x_range]).reshape(-1, 1)\n",
    "  \n",
    "    axarr2[idx[0], idx[1]].plot(x_range, y_range_predict, color='r')\n",
    "    axarr2[idx[0], idx[1]].scatter(x_krr_train, y_krr_train, alpha=0.8)\n",
    "    axarr2[idx[0], idx[1]].set_title(tt)\n",
    "    axarr2[idx[0], idx[1]].set_xlim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-D GBM visualization - SVM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting decision regions\n",
    "x_min, x_max = x_train[:, 0].min() - 1, x_train[:, 0].max() + 1\n",
    "y_min, y_max = x_train[:, 1].min() - 1, x_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "f, axarr = plt.subplots(2, 3, sharex='col', sharey='row', figsize=(10, 8))\n",
    "\n",
    "for idx, i, tt in zip(product([0, 1], [0, 1, 2]),\n",
    "                       [1, 5, 10, 20, 50, 100], \n",
    "                       ['n_estimator = {}'.format(n) for n in [1, 5, 10, 20, 50, 100]]):\n",
    "    \n",
    "    gbt = gradient_boosting(n_estimator=i, pseudo_residual_func=pseudo_residual_L2, max_depth=2)  \n",
    "    gbt.fit(x_train, y_train)\n",
    "                   \n",
    "    Z = np.sign(gbt.predict(np.c_[xx.ravel(), yy.ravel()]))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha=0.4)\n",
    "    axarr[idx[0], idx[1]].scatter(x_train[:, 0], x_train[:, 1], c=y_train_label, alpha=0.8)\n",
    "    axarr[idx[0], idx[1]].set_title(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-D GBM visualization - KRR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_size = 0.001\n",
    "x_range = np.arange(0., 1., plot_size).reshape(-1, 1)\n",
    "\n",
    "f2, axarr2 = plt.subplots(2, 3, sharex='col', sharey='row', figsize=(15, 10))\n",
    "\n",
    "for idx, i, tt in zip(product([0, 1], [0, 1, 2]),\n",
    "                       [1, 5, 10, 20, 50, 100], \n",
    "                       ['n_estimator = {}'.format(n) for n in [1, 5, 10, 20, 50, 100]]):\n",
    "    \n",
    "    gbm_1d = gradient_boosting(n_estimator=i, pseudo_residual_func=pseudo_residual_L2, max_depth=2)  \n",
    "    gbm_1d.fit(x_krr_train, y_krr_train)\n",
    "    \n",
    "    y_range_predict = gbm_1d.predict(x_range)\n",
    "\n",
    "    axarr2[idx[0], idx[1]].plot(x_range, y_range_predict, color='r')\n",
    "    axarr2[idx[0], idx[1]].scatter(x_krr_train, y_krr_train, alpha=0.8)\n",
    "    axarr2[idx[0], idx[1]].set_title(tt)\n",
    "    axarr2[idx[0], idx[1]].set_xlim(0, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
